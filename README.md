# Stressnet Dashboard: Technical Specification & Design Document

## 1. Executive Summary
The Stressnet Dashboard is a lightweight, self-hosted visualization tool designed to monitor the health and performance of the Layer 1 blockchain integration environment ("stressnet"). It ingests JSON reports generated by the `txgen` traffic generator, filters out infrastructure noise, and uses statistical baselining to surface legitimate code regressions versus operational failures.

The system is architected as a local-first web application (React/TypeScript) running directly on the test infrastructure, utilizing a file-system-based "database" (in-memory state) to ensure simplicity and ease of deployment.

---

## 2. Problem Statement & Goals

### 2.1 The Problem
The current stress testing workflow produces high volumes of raw JSON data. Developers face several challenges:
* **Noise vs. Signal:** Distinguishing between a network outage (Ops issue) and a client regression (Code issue) requires manual log parsing.
* **Lack of Context:** A report showing "85% drop rate" is alarming in isolation but might be normal for a specific saturation test configuration.
* **No Historical Baseline:** It is difficult to determine if the current build is performing "better" or "worse" than previous builds without manually comparing files.

### 2.2 Design Goals
1.  **Triage Hierarchy:** Automatically categorize failures into "Ops/Infra Failure" (ignore) vs. "Workload Regression" (investigate).
2.  **Statistical Baselining:** Use rolling averages (EMA) and deviation metrics (MAD) to flag anomalies based on historical performance of specific workloads, not arbitrary static thresholds.
3.  **Architecture Simplicity:** No external database (Postgres/MySQL). No complex auth. The system must run via a simple `npm start` on the existing `txgen` box.
4.  **Deterministic Logic:** Core analysis logic must be pure functions, separated entirely from I/O, allowing for robust unit testing.

---

## 3. Conceptual Workflow: The Triage Funnel

The system processes data through three logical layers before presenting it to the user:

1.  **Layer 1: Validity Check (The Ops Filter)**
    * *Input:* Raw JSON Report.
    * *Logic:* Did the test actually run?
    * *Criteria:* If `txs_committed == 0` OR `all_rpcs_failed == true`, the run is classified as `OPS_FAILURE`.
    * *Action:* These runs are displayed on the timeline but **excluded** from statistical baseline calculations to prevent poisoning the data.

2.  **Layer 2: Baseline Comparison (Regression Detection)**
    * *Input:* Valid "Green" or "Red" runs.
    * *Logic:* Compare current `Committed TPS` and `Drop Rate` against the historical Exponential Moving Average (EMA).
    * *Criteria:*
        * **RED:** Metric deviates > 2 deviations (Sigma) from baseline.
        * **YELLOW:** Metric deviates > 1 deviation.
        * **GREEN:** Metric is within normal variance.
    * *Action:* Only Green/Yellow runs update the baseline. Red runs are flagged for human review.

3.  **Layer 3: Root Cause Context**
    * *Input:* A flagged "Red" run.
    * *Action:* The UI surfaces the specific Workload Hash (Configuration) and links the Build Version to the git commit history (via GitHub API) to identify recent changes.

---

## 4. Technical Architecture

The project is structured as a TypeScript Monorepo to enforce separation of concerns.

### 4.1 Module Structure
* **`packages/core` (Pure Logic):** Contains all statistical math, hashing algorithms, and classification rules. **Zero dependencies on Node.js runtime, File System, or Network.**
* **`packages/server` (IO & State):** A Node.js/Express server. Handles file watching, JSON parsing, and maintains the in-memory state of the world.
* **`packages/client` (UI):** A React + Vite application. Fetches pre-digested state from the server.

### 4.2 Data Flow
1.  **Ingest:** `fs.watch` detects a new `.json` report in the configured directory.
2.  **Debounce:** Server waits 500ms to ensure file write completion.
3.  **Parse & Hash:** Server parses JSON; `core` computes a deterministic hash of the workload configuration.
4.  **Analyze:** `core` compares the report against the in-memory `WorkloadBaseline`.
5.  **Update:**
    * If `OPS_FAILURE` or `RED`: State is saved, baseline is untouched.
    * If `GREEN`: State is saved, baseline is updated via EMA logic.
6.  **Serve:** Client polls (or uses SSE) to fetch the latest `BuildSummary[]`.

---

## 5. Core Logic Specifications

### 5.1 Workload Identity (Hashing)
We cannot rely on `JSON.stringify` due to non-deterministic key ordering. We must implement a semantic hash.
* **Formula:** ``Hash = ${Group.Name}::${TrafficGen[0].TPS}::${TrafficGen[0].GenModeKey}``
* **Rationale:** A workload named "Native Transfer" running at 4,000 TPS is physically different from the same workload at 20,000 TPS. They require separate baselines.

### 5.2 Baseline Calculation (EMA)
To smooth out noise while adapting to legitimate performance drift, we use an Exponential Moving Average.
* **Smoothing Factor (`alpha`):** `0.2` (Retains memory of ~10-15 runs).
* **Metrics Tracked:**
    1.  `Mean` (The average value).
    2.  `MAD` (Mean Absolute Deviation - preferred over StdDev for robustness against outliers).
* **Update Logic:**
    ``NewMean = (alpha * Current) + ((1 - alpha) * OldMean)``

### 5.3 Ops Failure Detection
A run is strictly an "Ops Issue" if:
1.  `txs_committed` is exactly 0.
2.  **OR** The `rpc_stats` array exists, is non-empty, AND every RPC endpoint shows `success: 0`.

---

## 6. Data Models

### 6.1 The Report (Input)
Derived from `txgen` output.
``typescript
interface TxGenReport {
  start_time: string;
  client_version: string; // e.g., "Monad/0.0-3de84fa"
  config: {
    workload_groups: {
      name: string;
      traffic_gens: { tps: number; gen_mode: any }[];
    }[];
  };
  rpc_stats: { success: number; url: string }[]; // New field
  txs_committed: number;
  txs_dropped: number;
  txs_sent: number;
}
``

### 6.2 The Processed Run (Internal State)
The enriched object sent to the UI.
``typescript
interface ProcessedRun {
  reportId: string;       // Filename
  workloadHash: string;   // Unique ID for baseline lookup
  buildVersion: string;
  status: 'GREEN' | 'YELLOW' | 'RED' | 'OPS_FAILURE';
  metrics: {
    tps: number;
    dropRate: number;
  };
  deviation: {            // Percentage diff from baseline
    tps: number;
    dropRate: number;
  };
}
``

---

## 7. UI/UX Design

### 7.1 Landing Page: "The Executive Timeline"
* **Vertical Timeline:** Ordered by Build Version (descending).
* **Build Card:**
    * **Traffic Light:** Overall status of the build (Red if *any* workload regressed, Grey if majority Ops Failure).
    * **Ops Stability:** "% Time in Ops Issues" (e.g., "10% runs failed to start").
    * **Throughput Delta:** Aggregate performance shift (e.g., "â–¼ 5% overall").

### 7.2 Build Detail: "Triage View"
* **Zone A (Regressions):** Cards for specific workloads flagged as `RED`.
    * *Display:* "Expected 2% drop rate, got 85%."
    * *Action:* Click to view commit history for this version.
* **Zone B (Healthy):** Collapsed list of `GREEN` workloads to confirm test coverage.

### 7.3 Context Drawer (Investigation)
* **Trigger:** Clicking a Build Version or Regression Card.
* **Content:**
    * Parses the short SHA from `client_version` (e.g., `3de84fa`).
    * Fetches commit messages between `Current_SHA` and `Last_Green_SHA`.
    * Displays a concise changelog to correlate code changes with performance drops.

---

## 8. Implementation Plan

1.  **Phase 1: Core Logic (TDD)**
    * Implement `computeWorkloadHash`, `isOpsFailure`, and `updateBaseline` in `packages/core`.
    * Write unit tests with mock JSON data to verify EMA math and edge cases.

2.  **Phase 2: Server Scaffold**
    * Setup Express + `fs.watch`.
    * Implement the in-memory `State` object.
    * Verify it can ingest the existing 100+ JSON files without crashing.

3.  **Phase 3: UI Skeleton**
    * Build the Timeline component using React/Tailwind.
    * Connect to `/api/timeline` to visualize the data.

4.  **Phase 4: Refinement**
    * Tune the `alpha` (smoothing) and `sigma` (threshold) constants based on real data observation.